---
layout: post
title: Analysis of Recommendation Algorithms for E-Commerce
# image: 
#   path: /assets/img/blog/jeremy-bishop@0,5x.jpg
description: >
  E-Commerce의 등장으로 부각받는 추천시스템에 대해 살펴보고, 전통적 방법과 협업필터링 방법을 비교해보는 논문입니다.
sitemap: false
---

<!-- Version 9 is the most complete version of Hydejack yet.
{:.lead}

[Modernized](#linking-in-style) [design](#whats-in-the-cards), [big headlines](#ready-for-the-big-screen), big new features: [Built-In Search](#built-in-search), [Sticky Table of Contents](#sticky-table-of-contents), and [Auto-Hiding Navbar](#auto-hiding-navbar). That [and more](#and-much-more) is Hydejack 9.

- Table of Contents
{:toc .large-only} -->
## Introduction(서론)

추천시스템 논문에 본격적으로 들어가기에 앞서 서론 부분에 대해 살펴보겠습니다. 
요즈음 일상에서 우리는 E-Commerce라는 용어를 자주 접한다는 것을 많이 느끼실텐데요.
E-Commerce는 우리말로 하면 '전자 상거래'라는 뜻으로 대표적인 사이트로는 
아마존[Amazon](https://www.amazon.com/)이 있습니다. 이런 E-Commerce사이트에서는
고객들에게 수백만 가지의 상품을 제공하고 있어요. 제품이 너무 많다보니 저 역시 
이런 E-Commerce사이트에서 물건을 고르는 데 시간이 많이 걸렸는데요, 
이러한 문제점을 해결하기 위해 **추천시스템**이 등장하여 E-Commerce와 결합하였습니다.
추천시스템과 관련된 기법은 여러 가지가 있지만 그 중 **협업 필터링(CF)**기법은
가장 성공적이고 쉬운 모델 중 하나라고 여겨지고 있다고 해요. 그래서 이 논문에서 
협업 필터링에 대해 많이 다루고 있는거 같습니다. 그렇지만 협업 필터링이 당면한 과제는 
아래와 같습니다. 
- 알고리즘의 확장성
- 고객을 위한 추천의 질(quality)를 향상시키는 것
   - 특히 false positives(고객이 좋아하지 않는 물건 추천)

그럼 이번 논문에서 주로 어떤 내용을 다루는지 궁금하지 않으신가요?
이번 논문에서 다룰 내용은 크게 두 가지로 나눠서 볼 수 있습니다.
- 서로 다른 추천시스템에 대한 체계적인 실험적 평가를 제공
- E-commerce에서 흔한 희귀한 데이터에 맞는 새로운 알고리즘 개발

이번 논문에서 사용한 데이터셋은 **대형 E-Commerce(Fingerhut Coperations )**와
연구자가 직접 개발한 **[자체 추천리스템 리서치 사이트(MovieLens)](www.movielens.umn.edu)**입니다.

다음으로 연구의 목적 또는 기여하고자 하는 바에 대해 살펴보겠습니다. 
기여하고자 하는 바는 아래와 같이 세 가지로 요약할 수 있습니다.
- E-Commerce 사이트의 실제 데이터에 대한 추천시스템의 효과 분석
- original 협업 필터링&차원축소에 기반한 알고리즘&전통데이터알고리즘의 성능 비교
- 이전에 연구된 알고리즘보다 효율적이고, 매우 희귀한 데이터에서 퀄리티가 좋은 
  새로운 추천시스템 형성에 대한 접근

마지막으로 연구의 이론적 배경에 대해 살펴보겠습니다. 이론적 배경에 대해 간단히 살펴보고 넘어가면
논문 내용이 더 쉽게 다가온다는 생각이 들었습니다. 논문이 주로 **추천시스템 및 알고리즘 비교**이기 때문에
이 부분은 간략히 살펴보겠습니다. 이론적 배경으로는 크게 **KDD(Knowledge Discovery in Databases)**와
**차원 축소(Dimensionality Reduction)**이 있습니다. 
#### KDD(Knowledge Discovery in Databases)

KDD는 쉽게 말해 우리가 알고 있는 **데이터마이닝**이라고 생각하면 됩니다.
추천시스템에서도 데이터마이닝 방법이 사용되고 있는데, 
그 중 가장 많이 사용되는 방법이 **연관규칙**입니다. 
#### 차원축소(Dimensionality Reduction)

차원축소는 말 그대로 차원을 축소하는 기법인데, 추천시스템에서는
행렬의 행 또는 열을 축소시키는 것을 이야기하고 있습니다. 
차원축소기법 중 **주성분분석(PCA)**가 널리 이용되고 있으며,
**특이값 분해(SVD)**를 활용한 **LSI(잠재의미색인)**기법도 이용되고 있습니다.
## 방법론

서론에 대해 살펴본 후, 추천시스템의 방법론에 대해 살펴보겠습니다. 추천시스템의 방법론에서는 
아래와 같은 내용 순서대로 살펴보고 있었습니다.
- 추천시스템
- 전통적 데이터마이닝(연관규칙)
- 협업필터링

#### 추천시스템

방법론에서 먼저 등장한 내용은 추천시스템에 대한 전반적이 내용이었습니다. 
추천시스템에서 핵심 내용은 **<span style='color:red'>상위 N개의 항목을 생성하는 것</span>**입니다.
이러한 N개의 항목을 토대로 추천시스템은 E-Commerce사이트에서 고객들이 원하는 제품을 선택하는 데
도움을 주고 있습니다. 논문에 등장하는 기술은 아래와 같이 두 가지가 있습니다.
- 연관규칙 : 상위N개의 항목을 생성하는 데 얼마나 효율적으로 이용되는가
- 협업 필터링 : 3가지 방법으로 나눠서 살펴볼 예정

#### 전통적 데이터 마이닝(연관규칙)

E-Commerce 사이트에서 적용되는 데이터마이닝 방법 중 **연관규칙**이 가장 많이 사용되고 있습니다.
연관규칙은 **A를 구매하면 B를 구매한다**식으로 이야기할 수 있으며 이를 기호를 사용하면
**<span style='color:red'>A->B</span>**로 표시할 수 있습니다.
지지도의 평가지표로는 **지지도**, **신뢰도**, **향상도**가 있는데, 논문에서는
**지지도**와 **신뢰도**를 사용하였습니다.
- 지지도(support)
  - 전체 상품 중 A와 B를 동시에 구매할 확률(교집합)
- 신뢰도(confidence)
  - A를 구매했을 때 B도 구매할 확률(조건부 확률)

마지막으로 연관규칙을 활용하여 상위 N개 항목을 어떻게 생성하는지에 대해 살펴보겠습니다. 
1. 연관규칙 도출 및 사용
 - 임의로 설정한 최소 지지도와 최소 신뢰도를 넘는 연관규칙을 선택함.
2. 고객이 동시에 구매하는 규칙 확인(supported by customer)
3. support기반으로 도출된 항목을 신뢰도에 기반하여 정렬하기
  - 신뢰도가 높을수록 상위 항목임.
4. 상위 N개 항목을 추천항목으로 선정

#### 협업 필터링(Collaborative Filtering)

논문을 살펴보면 협업 필터링은 **다른 고객들의 의견**을 토대로 상품을 추천한다고 하였습니다.
협업 필터링은 **협업**이라는 말에서 알 수 있듯이 사용자들의 이웃이 형성된 후 
여러 알고리즘을 활용하고 있습니다. 앞에서 언급하였듯이 협업 필터링 방법을
세 가지로 나눠서 살펴보려고 합니다. 
##### 1. representation

representation에서는 **행렬**과 관련된 내용이 등장하게 됩니다. 먼저, 논문에서
**original representation**이라는 내용이 등장하였습니다. original representation은
**고객-제품 행렬(m x n)**을 나타내며, 고객이 물건을 구매하면 1, 구매하지 않으면 0으로
채워지는 행렬입니다. 이러한 original representation이 가지고 있는 문제점은 3가지가 있으며,
아래에서 각각에 대해 살펴보도록 하겠습니다.
- 희소성(sparsity)
  - 아마존과 같은 E-Commerce 사이트에서 우리는 수백만 가지의 다양한 아이템들을 접해볼 수 있습니다.
    하지만 우리는 대부분 한두가지의 물건을 구매합니다. 그리고 이렇게 구매하는 고객들의 비율은 
    매우 적게 나타나고 있습니다(1%이하). 즉, 다양한 물건 대비 실구매자 수가 매우 적게 나타나는
    **희소성(sparsity)**이 E-Commerce에서 빈번하게 나타나고 있어요. 이러한 희소성 때문에
    최근접이웃 알고리즘이 특정 고객에게 제대로 된 추천을 하지 못하는 **reduced coverage**도
    빈번히 나타나고 있습니다.
- 확장성(scalability)
  - 전자상거래 사이트 등장 초기에 비해 요즈음 사이트에서 제공하는 물건이 수백만가지로 늘어났고,
    이에 걸맞게 전자상거래 사이트 이용 고객도 증가하였습니다. 특히 예전에는 직접 마트나 시장에 가서
    물건을 고르는 일이 일상이었는데, 지금은 인터넷이나 스마트폰을 이용해 전자상거래를 이용하는 것이
    일상이 되었습니다. 이제 추천시스템도 폭발적으로 증가한 고객과 제품에 맞게 변모해야 한다는 점에서
    확장성의 문제가 대두되고 있습니다.
- 유의성(synonymy)
  - 우리가 물건을 살 때 유사한 물건이지만 다른 이름을 가지는 경우를 볼 수 있습니다. 
    실제로 두 물건은 같은 품목이지만 이름이 다르다는 이유로 **상관관계 기반 추천시스템**은 
    다른 물건으로 인식하여 제대로 된 추천을 하지 못합니다. 쉬운 예로 보면,
    고객 A가 양면 색종이를 구매하고, 고객 B가 단면 색종이를 구매하였다면 
    추천시스템은 두 고객이 아예 대른 물건을 구매한 것으로 인식하게 됩니다.
    이러한 현상 때문에 **내재된(latent)** 규칙을 찾지 못하게 됩니다.

이러한 문제점을 해결하기 위해 **LSI를 활용한 차원축소 방법**이 등장하였습니다.
LSI를 활용하면 기존의 (n x m) 행렬이 (n x k) 행렬로 차원축소가 됩니다. k는 절사된(truncated) SVD를
활용된 것에서 유래하는데, 이를 이해하려면 선형 대수부분이 들어와야하기 때문에 LSI로 차원축소하면
k가 등장한다 정도만 이야기하고 넘어가겠습니다. **축소된 차원표현**이 갖는 장점은 아래와 같습니다.
- 모든 고객들의 의견이 존재하기 때문에 희소성 문제 해결
- 처리 시간과 저장요구 모두 개선됨.
- 내재된 규칙을 찾음으로써 유의성 문제 해결
  
##### 2. Neighborhood Formation(이웃 형성)-근린 형성 알고리즘

논문에서 살펴보는 근린 형성 알고리즘은 아래와 같이 두 가지가 있습니다.
- 중심 기반(Center_based) 알고리즘
  - 이 알고리즘은 특정 고객으로부터 가장 가까운 고객을 형성함으로써 
    이웃을 형성하는 방법입니다.
- Aggregate Neighborhood
  - 이 방법은 먼저, 처음 이웃은 **중심기반 알고리즘**방식을 활용하여
    특정 크기(l)의 이웃을 형성합니다. 그 후 **<span style='color:red'>이웃의 크기가 특정 크기와 같아질 때까지</span>**
    이웃의 중심을 계산한 후 그 중심에서 가장 가까운 고객을 다음((l+1)st)이웃으로 설정하는 작업을 반복합니다.
    세미나를 통해 중심기반 알고리즘과 Aggregate Neighborhood은 거의 동일한 방법이라는 것을 알게 되었습니다.
#### 3. Generation of Recommendation(추천 생성) – 협업 필터링의 최종 단계

이웃을 형성한 후 최종적으로 추천을 생성하는 단계입니다. 추천생성 방법으로는 크게 아래와 같이 
두 가지로 나눠서 살펴볼 수 있습니다. 
- 빈발품목(Most-frequent Item Recommendation)
  - 제품의 빈도수를 이용하여 실제 구매자가 아직 구매하지 않은 가장 빈번한 N개를 추천해주는 방법
- 연관규칙 기반 추천(Association Rule-based Recommendation)
  - 이 방법은 전체가 아닌 특정 이웃만을 규칙 생성할 때 고려하는데, 때문에 만족스럽지 못한 추천이
    생성될 수 있다는 특징이 있음.

## 평가 및 결과
#### 데이터 셋
논문에서는 데이터 셋을 훈련용:테스트용 분할 비율을 8:2로 설정하였습니다. 
그리고 영화리뷰 데이터인 ML의 희소성은 0.9369이며, E-Commerce데이터인
MC의 희소성은 0.9994로 나타났습니다. 희소성이 매우 높아서 유의하지 못하다는 질문을 할 수 있는데,
데이터의 희소성의 기본값이 0.9점대라서 희소성이 이렇게 나타난 것입니다.
#### 평가지표

논문에서 사용된 평가지표로는 **민감도**, **정밀도**, 그리고 **F1-score**가 있습니다.
추천시스템의 경우, 추천품목(N또는 k가 많이 사용됨)이 고정되어 있기 때문에 
우리가 평소에 알던 평가지표와는 다르게 생각해야 합니다. 그럼 각각 평가지표를 어떻게 
생각해야 하는지 살펴보고 넘어가겠습니다. 
- 민감도(recall)
  - 사용자가 관심있는 품목 중 추천하는 품목이 차지하는 비율
- 정밀도(precision)
  - 추천하는 품목 중 사용자가 실제로 관심있는 품목이 차지하는 비율
- F1-score
  - 민감도와 정밀도의 경우 trade-off(상충관계)에 놓여 있음.
  - 만약 추천품목 개수를 증가시키면 민감도는 증가시키지만 정밀도는 감소됨
  - 두 지표 모두 중요하기 때문에 두 지표의 **조화평균**을 활용한 F1-score가 등장함.
#### 실험 결과

실험 결과는 **이웃의 크기**, **차원(k)의 수**, **추천형성 프로세스**,
**이웃형성 프로세스**, 그리고 **밀도 민감도 분석**측면으로 나눠서 살펴보도록 할게요.
##### 1. 이웃의 크기

이웃의 크기는 분류한 데이터셋과 분류하지 않은 데이터셋이 성능이 같게 나왔습니다.
그러나 과대적합과 같이 어느 특정 이웃의 크기를 넘어가면 오히려 성능이 떨어진다는 
사실이 나타났습니다. 또한 데이터셋에 따라 최적의 이웃 크기가 다른 것도 알 수 있었습니다.
##### 2. 차원(k)의 수

앞서 언급했듯이, 차원은 줄어든 열, 즉 k값을 의미하고 있습니다. ML데이터는 이웃의 크기와 
같은 모습을 보이지만 MC데이터는 k의 수를 증가시키면 성능이 계속 좋아지는 것을 알 수 있습니다. 
이는 MC데이터가 ML데이터보다 **<span style='color:red'>행렬의 크기가 더 크고, 희소성은 더 높기 때문에**</span>
성능이 더 높게 나타나고 있었습니다.
##### 3. 추천형성 프로세스

앞서 추천형성 프로세스로 빈발항목추천과 연관규칙 추천 방법이 있다고 살펴보았습니다. 
그러나 실험 결과 두 추천 방법 간 성능 차이는 거의 없는 것으로 나타났습니다.
##### 4. 이웃형성 프로세스

이 실험에서는 중심기반 알고리즘이 Aggregate Neighborhood방법보다 성능이 더 뛰어나다는 것을 알 수 있었습니다. 
특히, 이는 EC데이터에서 더 두드러졌는데요, 이를 통해 희소한 데이터가 추천의 성능을 떨어뜨릴 것이라는 예상을 
빗나가게 되었습니다.
##### 5 . 밀도 민감도 분석

마지막으로 밀도와 관련되서 살펴보겠습니다. 밀도는 크게 100%, 80%, 60%, 40%, 그리고 20%로 나눠서 보았으며,
협업필터링기법과 연관규칙 기법으로 나눠서 살펴보았습니다. 실험 결과, 협업 필터링의 성능이 연관규칙 기법보다
성능이 뛰어났으며, 이는 특정 밀도에서 더 두드러졌습니다. 협업 필터링에서 살펴보면, ML의 경우 더 낮은 차원에서
좋은 성능을 보인 반면, MC의 경우 더 낮은 차원에서 좋은 성능을 보이고 있었습니다. 이는 두 데이터 간 행렬의
크기와 희소성의 차인에서 기인하였다고 할 수 있습니다.
#### 요약

지금까지 논문에 대해 길게 살펴보았는데요, 짧게 요약하며 글을 마무리하려고 합니다.
E-Commerce사이트에서 추천시스템은 매우 중요한 툴로 자리잡고 있습니다. 그 중 협업 필터링 기법이 
많이 사용되고 있었는데요, **차원축소 기법**은 협업 필터링의 확장성을 높이고, 질 좋은 추천을 하는 데 
기여하고 있습니다. 하지만 차원축소가 왜 추천시스템에서 잘 적용되는지에 대해서는 추가적인 연구가 
필요하다고 하면서 마무리하였습니다. 
